{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVS9IqzGak-Q",
        "outputId": "293e7604-8dcd-460a-9547-5cf4a2bb06bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAyXuVMfa2i7"
      },
      "outputs": [],
      "source": [
        "train_path=\"/content/drive/MyDrive/part_A_final/train_data\"\n",
        "test_path=\"/content/drive/MyDrive/part_A_final/test_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVG7fyEqfjja",
        "outputId": "8a618afc-235d-405b-df0a-f5a06fac69d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'image_info'])\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import loadmat\n",
        "\n",
        "mat = loadmat(\"/content/drive/MyDrive/part_A_final/test_data/ground_truth/GT_IMG_1.mat\")  # Replace gt_path with the path to one of your .mat files\n",
        "print(mat.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QNDASwvfz8m"
      },
      "outputs": [],
      "source": [
        "mat = loadmat(\"/content/drive/MyDrive/part_A_final/test_data/ground_truth/GT_IMG_1.mat\")\n",
        "image_info = mat['image_info']\n",
        "print(image_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GwpYOmxVj4K5",
        "outputId": "407be26e-fab9-40a3-b8ef-811dc275a9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/part_A_final/train_data/images'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6c3ed6eff817>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-6c3ed6eff817>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading datasets...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrowdDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrowdDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_gt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-6c3ed6eff817>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, image_dir, gt_dir, transform, output_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_size\u001b[0m  \u001b[0;31m# Target size for resizing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/part_A_final/train_data/images'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from scipy.io import loadmat\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "\n",
        "def generate_density_map(image_shape, points):\n",
        "\n",
        "    density_map = np.zeros(image_shape, dtype=np.float32)\n",
        "    for point in points:\n",
        "        x, y = int(point[0]), int(point[1])\n",
        "        if x >= image_shape[1] or y >= image_shape[0]:\n",
        "            continue\n",
        "        density_map[y, x] += 1\n",
        "    density_map = gaussian_filter(density_map, sigma=15)\n",
        "    return density_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class CrowdDataset(Dataset):\n",
        "    def __init__(self, image_dir, gt_dir, transform=None, output_size=(256, 256)):\n",
        "        self.image_dir = image_dir\n",
        "        self.gt_dir = gt_dir\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "        self.transform = transform\n",
        "        self.output_size = output_size  \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        gt_path = os.path.join(self.gt_dir, f\"GT_{self.image_files[idx][:-4]}.mat\")\n",
        "\n",
        "       \n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        mat = loadmat(gt_path)\n",
        "        image_info = mat['image_info']\n",
        "        locations = image_info[0][0][0][0][0]\n",
        "\n",
        "        density_map = generate_density_map(img.shape[:2], locations)\n",
        "\n",
        "        img = cv2.resize(img, self.output_size)\n",
        "        density_map = cv2.resize(density_map, self.output_size)\n",
        "        density_map = density_map * (np.sum(density_map) / np.sum(density_map))\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        density_map = torch.tensor(density_map, dtype=torch.float32).unsqueeze(0)\n",
        "        return img, density_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DepthEmbeddedLCDnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DepthEmbeddedLCDnet, self).__init__()\n",
        "        self.depth_encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(80, 128, kernel_size=1, stride=1)\n",
        "        self.output = nn.Conv2d(128, 1, kernel_size=1, stride=1)\n",
        "\n",
        "    def forward(self, img, depth):\n",
        "        depth_features = self.depth_encoder(depth)\n",
        "\n",
        "        x = torch.relu(self.conv1(img))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x1 = torch.relu(self.conv3(x))\n",
        "        x2 = torch.relu(self.conv4(x1))\n",
        "        x3 = torch.relu(self.conv5(x2))\n",
        "\n",
        "        combined = torch.cat((x3, depth_features), dim=1)\n",
        "        x4 = torch.relu(self.conv6(combined))\n",
        "        out = self.output(x4)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def train_model(model, dataloader, optimizer, criterion, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        print(f\"Starting epoch {epoch+1}/{num_epochs}...\")\n",
        "        for batch_idx, (img, gt_density) in enumerate(dataloader):\n",
        "            img, gt_density = img.to(device), gt_density.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            depth = torch.mean(img, dim=1, keepdim=True)\n",
        "            pred_density = model(img, depth)\n",
        "\n",
        "            loss = criterion(pred_density, gt_density)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1} completed. Average Loss: {epoch_loss/len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def test_model(model, dataloader, device):\n",
        "    print(\"Starting testing...\")\n",
        "    model.eval()\n",
        "    mae = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (img, gt_density) in enumerate(dataloader):\n",
        "            img, gt_density = img.to(device), gt_density.to(device)\n",
        "            depth = torch.mean(img, dim=1, keepdim=True)\n",
        "            pred_density = model(img, depth)\n",
        "            mae += torch.abs(pred_density.sum() - gt_density.sum()).item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f\"Processed batch {batch_idx+1}/{len(dataloader)}...\")\n",
        "\n",
        "    print(\"Testing completed.\")\n",
        "    return mae / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    train_img_dir = \"/content/drive/MyDrive/part_A_final/train_data/images\"\n",
        "    train_gt_dir = \"/content/drive/MyDrive/part_A_final/train_data/ground_truth\"\n",
        "    test_img_dir = \"/content/drive/MyDrive/part_A_final/test_data/images\"\n",
        "    test_gt_dir = \"/content/drive/MyDrive/part_A_final/test_data/ground_truth\"\n",
        "\n",
        "    print(\"Loading datasets...\")\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_dataset = CrowdDataset(train_img_dir, train_gt_dir, transform, output_size=(256, 256))\n",
        "    test_dataset = CrowdDataset(test_img_dir, test_gt_dir, transform, output_size=(256, 256))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
        "    print(\"Datasets loaded successfully.\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = DepthEmbeddedLCDnet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    train_model(model, train_loader, optimizer, criterion, device, num_epochs=3)\n",
        "    print(\"Training completed.\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"depth_embedded_lcdnet.pth\")\n",
        "    print(\"Model saved to depth_embedded_lcdnet.pth\")\n",
        "\n",
        "    mae = test_model(model, test_loader, device)\n",
        "    print(f\"Mean Absolute Error on Test Dataset: {mae:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1F-dRwd_tBT",
        "outputId": "54e36445-fbb9-409e-fa0e-5576db8dfeea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Trainable Parameters in DepthEmbeddedLCDnet: 100977\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = DepthEmbeddedLCDnet()\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total Trainable Parameters in DepthEmbeddedLCDnet: {total_params}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
