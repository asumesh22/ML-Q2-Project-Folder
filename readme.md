1. Abstract

Accurately estimating crowd density in images is of importance in applications such as public safety and event management. Our study proposes a new approach to crowd counting using a depth-embedding LCDnet (Lightweight Crowd Density Estimation Model), which combines information regarding image depth with image features to predict crowd size. Our model improves on crowd counting accuracy, as measured by Mean Absolute Error (MAE) as compared to Lightweight models that do not use depth-embedding, while also improving runtime as compared to models that incorporate depth-embedding. After testing, our depth-embedded LCDnet model achieved a MAE of 112.64, which was lower than the MAE of only the LCDnet of 181.8, and expectedly higher than the MAE of the depth-embedding model which was 57.55.

2. Introduction

Crowd counting is an important logistical step when event planning. It is commonly used for public safety and urban planning purposes. However, traditional methods often struggle with problems like occlusions (objects being hidden), varying crowd densities, and lighting changes. Using depth information in combination with standard images can improve accuracy by providing a better sense of the space and arrangement of people. This is especially useful for real-time applications, where computational efficiency is critical. The goal of this proposal is to create a lightweight model that uses both depth and image data to improve crowd counting in real-time settings.
Head annotations refer to the labeled locations of people's heads within an image. The 2D coordinates (x, y) that correspond to each person's head location in the picture are commonly used to express these comments. The coordinates for each head in the image are included in the annotation data, which is saved in.mat files with the file name matching the image file. The head annotations are used to generate density maps that represent the number of people in different regions of the image. These annotations serve as ground truth data for training and evaluating the crowd counting model.
Depth-embeddings refer to incorporating depth information into the crowd counting model. In traditional 2D image processing, depth data is not readily available, and the model relies solely on the visual appearance of the crowd to create the depth embeddings. Depth embeddings help by introducing information about the relative distance of objects (people) from the camera.
The input to our algorithm is an image with associated head annotations, which are stored in .mat files associated with the .jpg (image) files. We then use a light-weight model that uses depth-embeddings to output a predicted crowd density map.
